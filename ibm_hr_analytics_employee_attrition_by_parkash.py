# -*- coding: utf-8 -*-
"""IBM HR Analytics Employee Attrition_By Parkash.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OUhpMGwjFv9b1oCy3EIWhCPIcgruzN35

# **IBM HR ANALYTICS EMPLOYEE ATTRITION**

**Goal:** Predict which employees are at high risk of leaving the company.

**Problem Type:** This is a binary classification problem.

**Target:** The model's prediction will be "Yes" (employee will leave) or "No" (employee will stay).

Firstly, loading the data from our dataset csv file
"""

import pandas as pd
df = pd.read_csv(r'IBM HR Employee Attrition Data.csv')
df.head()

pd.options.display.max_columns = 50
df.head()

"""Gathering some info and taking overview of the data"""

df.info()

df.describe()

"""Checking for null values"""

df.isnull().sum()

"""Not a single null value, so we check for duplicates"""

df.duplicated().sum()

"""No duplicate values too, so nothing to handle

There are a few catagorical columns that we first need to convert to binary, such as:

**Attrition (1=YES, 0=NO)**, **Gender (1=MALE, 0=FEMALE)**, **Over18 (1=YES, 0=NO)** and **OverTime (1=YES, 0=NO)**
"""

df['Attrition'] = df['Attrition'].apply(lambda x: 1 if x == 'Yes' else 0)
df['Gender'] = df['Gender'].apply(lambda x: 1 if x == 'Male' else 0)
df['Over18'] = df['Over18'].apply(lambda x: 1 if x == 'Y' else 0)
df['OverTime'] = df['OverTime'].apply(lambda x: 1 if x == 'Yes' else 0)

"""There are few columns that we need to Hot-Encode and then drop them, such as:

**Business Travel, Department, EducationField, JobRole, Marital Status**

we will make dummies of the categories inside each of these columns and once we get the different dummy columns of those categories(having only 'True' or 'False' values), we will then drop the actual column
"""

df = df.join(pd.get_dummies(df['BusinessTravel'])).drop('BusinessTravel', axis = 1)
df = df.join(pd.get_dummies(df['Department'], prefix='Department')).drop('Department', axis = 1)
df = df.join(pd.get_dummies(df['EducationField'], prefix='Education')).drop('EducationField', axis = 1)
df = df.join(pd.get_dummies(df['JobRole'], prefix='JobRole')).drop('JobRole', axis = 1)
df = df.join(pd.get_dummies(df['MaritalStatus'])).drop('MaritalStatus', axis = 1)

df

# converting those 'True ' and 'False' values to 1 and 0
df = df.map(lambda x: 1 if x is True else 0 if x is False else x)
df

"""Now that we have converted all the categorical columns to numerical, we will further analyse the dataset for more cleaning"""

import matplotlib.pyplot as plt

df.hist(figsize=(20, 15))
plt.tight_layout()
plt.show()

"""There are lots of columns that are populated with only one value, such as:

**EmployeeCount is always 1 in every row, StandardHours is always 80 in every row, Over18 is also always 1, etc..(Not Including the ones we made dummies of, because obviously they would contain only 1 and 0(True and False))**
We don't necessarily need those, so let's just drop them out.
"""

# dropping EmployeeNumber also, because our prediction has nothing to do with the amount of employees
df = df.drop(['EmployeeNumber', 'EmployeeCount', 'Over18', 'StandardHours'], axis = 1)

df

"""**Model Training**

Using RandomForestClassifier from ensemble and also train_test_split model
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

X, y = df.drop('Attrition', axis = 1), df['Attrition']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

model = RandomForestClassifier(n_jobs=-1)

model.fit(X_train, y_train)

# evaluating the possible score of our model
model.score(X_test, y_test)

from sklearn.metrics import classification_report, confusion_matrix

y_pred = model.predict(X_test)

print("Classification Report:")
print(classification_report(y_test, y_pred))

"""Our 88% accuracy for 0 ('NO' People who are staying) looks good, but it's hiding a major problem. Our model is excellent at predicting who will stay, but it is very poor at predicting who will leave (which is our main goal).

**Class 0 (Stayed): The Good Results**
- Precision: 0.91 When our model predicts an employee will Stay, it is correct 91% of the time. (Good)

- Recall: 1.00 Our model successfully found 100% of all the employees who actually stayed. (Excellent)

**Class 1 (Left): The Bad Results**
- Precision: 1.00 This means that, Of the few employees our model predicted would Leave, it was 100% correct." It didn't raise any false alarms.

- Recall: 0.08 This is the critical failure. our model only found 23% of the employees who actually left. This means it completely missed the other 77% of employees who quit.

To solve this, we use a tecknique called "SMOTE", this works by generating new, synthetic examples for the minority class, rather than simply duplicating existing ones.
"""

from imblearn.over_sampling import SMOTE

sm = SMOTE(random_state=42)

X_train_resampled, y_train_resampled = sm.fit_resample(X_train, y_train)

print(f"Training shape: {X_train_resampled.shape}")
print(f"Training target counts: \n{y_train_resampled.value_counts()}")

model = RandomForestClassifier(n_jobs=-1, random_state=42)

model.fit(X_train_resampled, y_train_resampled)

y_pred = model.predict(X_test)

print("\nClassification Report (After SMOTE):")
print(classification_report(y_test, y_pred))

"""Now that we have the model ready, let's see what are the feature importances from our entire dataset (meaning what column has what amount of importance for our result prediction)"""

importances = model.feature_importances_
feature_names = model.feature_names_in_

feature_importances = pd.DataFrame({
    'Feature': feature_names,
    'Importance': importances
})

feature_importances = feature_importance_df.sort_values(by='Importance', ascending=False)

print("Top 10 Features Driving Attrition:")
print(feature_importances.head(10))

import matplotlib.pyplot as plt

plt.figure(figsize=(20, 10))
plt.bar(feature_importances['Feature'], feature_importances['Importance'])
plt.xticks(rotation=45, ha='right')
plt.show()